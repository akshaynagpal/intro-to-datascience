{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1: Loading and Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to dive into the world of data science! With the growing collection of data in many different fields, data science has become an important tool in unlocking business value, developing a better understanding of situations, and solving problems in a principled fashion. We hope you come to enjoy and continue on to explore data science through this track. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This track will gently acquaint you with how people get started with a data problem; in particular, we will cover obtaining data, how data is usually stored, getting data into usable form in Python, doing exploratory work, and correcting for missing or unrecorded values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Data\n",
    "Before starting to work on a data problem, we need to actually get some data to analyze! Sometimes, this will be given to you directly, but often times, you'll have to go look for data that matches the problem you want to analyze. The good news is that there are an ever growing number of datasets you can find on the Internet! One of our favorite type of sources is government open data, which has information on all kinds of things that you both can and can't imagine. For the purpose of this level, we'll be using information on NYC Green Taxi trips during January 2016. You can find more information on this dataset [here](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml), and the actual data comes from [this link](https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2016-01.csv). For your convenience, it's already in the `datasets` folder as `green_tripdata_2016-01.csv`. You might find it helpful to go through [this data dictionary](http://www.nyc.gov/html/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf) later if there are columns that don't make sense to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Format\n",
    "Let's now understand how this data is stored; while there are other formats such as JSON, CSV, or comma-separated values, files are one of the most common file formats for data scientists. We'll look at a toy example about fake Columbia library traffic to familiarize ourselves:\n",
    "`date,library,number_students\n",
    "1-16-2017,butler,0\n",
    "1-16-2017,noco,0\n",
    "1-16-2017,watson,0\n",
    "1-17-2017,butler,100\n",
    "1-17-2017,noco,55\n",
    "1-17-2017,watson,67\n",
    "1-18-2017,butler,110\n",
    "1-18-2017,noco,48\n",
    "1-18-2017,watson,78\n",
    "1-19-2017,butler,35\n",
    "1-19-2017,noco,24\n",
    "1-19-2017,watson,18`\n",
    "The first thing to take note of is that all the different values are separated by commas: hence the name CSV. Another thing to notice is that the column names are given in the first row. The last important thing to note about CSV files is that each row is on its own line. There's not much more to CSV files than these few points, and their convenience makes them a file format of choice for data scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data into Python\n",
    "Now that we understand some of the basics of the data, let's try playing around with it in Python. One typical way to work with datasets is using `pandas`, which is a package which makes it easy to manipulate data stored in tabular form or as `pandas` more succintly says: dataframes. Let's load up `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also usually useful to have `numpy` around, and we'll use it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load our dataset using the `read_csv` function; it does pretty much exactly what the name implies: read data from a CSV and return the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi_data = pd.read_csv(\"datasets/green_tripdata_2016-01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have our data in Python. Let's start to explore it; the first thing we should check out is how much data we have in terms of the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1445285\n",
      "Number of columns: 21\n"
     ]
    }
   ],
   "source": [
    "number_rows = len(taxi_data.index)\n",
    "number_columns = len(taxi_data.columns)\n",
    "print(\"Number of rows: %d\" % number_rows)\n",
    "print(\"Number of columns: %d\" % number_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wowza! 1.4 million rows or so, guess we're dealing with big data. :) Another interesting thing to check out is what kinds of columns are included in the dataset: we can do this by checking out the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'lpep_pickup_datetime', 'Lpep_dropoff_datetime',\n",
      "       'Store_and_fwd_flag', 'RateCodeID', 'Pickup_longitude',\n",
      "       'Pickup_latitude', 'Dropoff_longitude', 'Dropoff_latitude',\n",
      "       'Passenger_count', 'Trip_distance', 'Fare_amount', 'Extra', 'MTA_tax',\n",
      "       'Tip_amount', 'Tolls_amount', 'Ehail_fee', 'improvement_surcharge',\n",
      "       'Total_amount', 'Payment_type', 'Trip_type '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(taxi_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot we can learn from just the columns that are stored: for example, we can get information like when the trip started and ended, where the trip started and ended, whether the people tipped, and how much the fare was.\n",
    "\n",
    "We can also investigate what types of data the columns have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "lpep_pickup_datetime      object\n",
       "Lpep_dropoff_datetime     object\n",
       "Store_and_fwd_flag        object\n",
       "RateCodeID                 int64\n",
       "Pickup_longitude         float64\n",
       "Pickup_latitude          float64\n",
       "Dropoff_longitude        float64\n",
       "Dropoff_latitude         float64\n",
       "Passenger_count            int64\n",
       "Trip_distance            float64\n",
       "Fare_amount              float64\n",
       "Extra                    float64\n",
       "MTA_tax                  float64\n",
       "Tip_amount               float64\n",
       "Tolls_amount             float64\n",
       "Ehail_fee                float64\n",
       "improvement_surcharge    float64\n",
       "Total_amount             float64\n",
       "Payment_type               int64\n",
       "Trip_type                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, looks like `pandas` isn't recognizing the times as such because it just labels it as `object`, which usually means string. Let's do that conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "lpep_pickup_datetime     datetime64[ns]\n",
       "Lpep_dropoff_datetime    datetime64[ns]\n",
       "Store_and_fwd_flag               object\n",
       "RateCodeID                        int64\n",
       "Pickup_longitude                float64\n",
       "Pickup_latitude                 float64\n",
       "Dropoff_longitude               float64\n",
       "Dropoff_latitude                float64\n",
       "Passenger_count                   int64\n",
       "Trip_distance                   float64\n",
       "Fare_amount                     float64\n",
       "Extra                           float64\n",
       "MTA_tax                         float64\n",
       "Tip_amount                      float64\n",
       "Tolls_amount                    float64\n",
       "Ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "Total_amount                    float64\n",
       "Payment_type                      int64\n",
       "Trip_type                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.lpep_pickup_datetime = pd.to_datetime(taxi_data.lpep_pickup_datetime)\n",
    "taxi_data.Lpep_dropoff_datetime = pd.to_datetime(taxi_data.Lpep_dropoff_datetime)\n",
    "taxi_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, much better. Now that we have some idea of what we'll be looking at, let's look at a few examples of trips. We'll do this using the `head` function, which will show us the first 5 rows. \n",
    "\n",
    "(Note that you could do `print(taxi_data.head())`, but the HTML table formatting that Jupyter lets us do looks much cleaner. To use the automatic formatting, just have the call to `head` be the last thing in your cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>Lpep_dropoff_datetime</th>\n",
       "      <th>Store_and_fwd_flag</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>Pickup_longitude</th>\n",
       "      <th>Pickup_latitude</th>\n",
       "      <th>Dropoff_longitude</th>\n",
       "      <th>Dropoff_latitude</th>\n",
       "      <th>Passenger_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_amount</th>\n",
       "      <th>Extra</th>\n",
       "      <th>MTA_tax</th>\n",
       "      <th>Tip_amount</th>\n",
       "      <th>Tolls_amount</th>\n",
       "      <th>Ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Payment_type</th>\n",
       "      <th>Trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:29:24</td>\n",
       "      <td>2016-01-01 00:39:36</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.928642</td>\n",
       "      <td>40.680611</td>\n",
       "      <td>-73.924278</td>\n",
       "      <td>40.698044</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:19:39</td>\n",
       "      <td>2016-01-01 00:39:18</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.952675</td>\n",
       "      <td>40.723175</td>\n",
       "      <td>-73.923920</td>\n",
       "      <td>40.761379</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:19:33</td>\n",
       "      <td>2016-01-01 00:39:48</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.971611</td>\n",
       "      <td>40.676105</td>\n",
       "      <td>-74.013161</td>\n",
       "      <td>40.646072</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:22:12</td>\n",
       "      <td>2016-01-01 00:38:32</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.989502</td>\n",
       "      <td>40.669579</td>\n",
       "      <td>-74.000648</td>\n",
       "      <td>40.689034</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:24:01</td>\n",
       "      <td>2016-01-01 00:39:22</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.964729</td>\n",
       "      <td>40.682854</td>\n",
       "      <td>-73.940720</td>\n",
       "      <td>40.663013</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime Lpep_dropoff_datetime Store_and_fwd_flag  \\\n",
       "0         2  2016-01-01 00:29:24   2016-01-01 00:39:36                  N   \n",
       "1         2  2016-01-01 00:19:39   2016-01-01 00:39:18                  N   \n",
       "2         2  2016-01-01 00:19:33   2016-01-01 00:39:48                  N   \n",
       "3         2  2016-01-01 00:22:12   2016-01-01 00:38:32                  N   \n",
       "4         2  2016-01-01 00:24:01   2016-01-01 00:39:22                  N   \n",
       "\n",
       "   RateCodeID  Pickup_longitude  Pickup_latitude  Dropoff_longitude  \\\n",
       "0           1        -73.928642        40.680611         -73.924278   \n",
       "1           1        -73.952675        40.723175         -73.923920   \n",
       "2           1        -73.971611        40.676105         -74.013161   \n",
       "3           1        -73.989502        40.669579         -74.000648   \n",
       "4           1        -73.964729        40.682854         -73.940720   \n",
       "\n",
       "   Dropoff_latitude  Passenger_count     ...      Fare_amount  Extra  MTA_tax  \\\n",
       "0         40.698044                1     ...              8.0    0.5      0.5   \n",
       "1         40.761379                1     ...             15.5    0.5      0.5   \n",
       "2         40.646072                1     ...             16.5    0.5      0.5   \n",
       "3         40.689034                1     ...             13.5    0.5      0.5   \n",
       "4         40.663013                1     ...             12.0    0.5      0.5   \n",
       "\n",
       "   Tip_amount  Tolls_amount  Ehail_fee  improvement_surcharge  Total_amount  \\\n",
       "0        1.86           0.0        NaN                    0.3         11.16   \n",
       "1        0.00           0.0        NaN                    0.3         16.80   \n",
       "2        4.45           0.0        NaN                    0.3         22.25   \n",
       "3        0.00           0.0        NaN                    0.3         14.80   \n",
       "4        0.00           0.0        NaN                    0.3         13.30   \n",
       "\n",
       "   Payment_type  Trip_type   \n",
       "0             1         1.0  \n",
       "1             2         1.0  \n",
       "2             1         1.0  \n",
       "3             2         1.0  \n",
       "4             2         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also just as easily look at the last 5 rows with the `tail` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>Lpep_dropoff_datetime</th>\n",
       "      <th>Store_and_fwd_flag</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>Pickup_longitude</th>\n",
       "      <th>Pickup_latitude</th>\n",
       "      <th>Dropoff_longitude</th>\n",
       "      <th>Dropoff_latitude</th>\n",
       "      <th>Passenger_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_amount</th>\n",
       "      <th>Extra</th>\n",
       "      <th>MTA_tax</th>\n",
       "      <th>Tip_amount</th>\n",
       "      <th>Tolls_amount</th>\n",
       "      <th>Ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Payment_type</th>\n",
       "      <th>Trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1445280</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-31 23:59:36</td>\n",
       "      <td>2016-02-01 00:07:53</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.807716</td>\n",
       "      <td>40.700451</td>\n",
       "      <td>-73.768478</td>\n",
       "      <td>40.698082</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445281</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-31 23:26:06</td>\n",
       "      <td>2016-01-31 23:31:22</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.951408</td>\n",
       "      <td>40.714001</td>\n",
       "      <td>-73.941483</td>\n",
       "      <td>40.724766</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445282</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-31 23:50:36</td>\n",
       "      <td>2016-01-31 23:56:19</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.954842</td>\n",
       "      <td>40.730213</td>\n",
       "      <td>-73.944626</td>\n",
       "      <td>40.726303</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445283</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-31 23:57:47</td>\n",
       "      <td>2016-02-01 00:06:58</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953491</td>\n",
       "      <td>40.817211</td>\n",
       "      <td>-73.977127</td>\n",
       "      <td>40.779583</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445284</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-31 23:59:54</td>\n",
       "      <td>2016-02-01 00:07:06</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.892578</td>\n",
       "      <td>40.747250</td>\n",
       "      <td>-73.910049</td>\n",
       "      <td>40.775539</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID lpep_pickup_datetime Lpep_dropoff_datetime  \\\n",
       "1445280         2  2016-01-31 23:59:36   2016-02-01 00:07:53   \n",
       "1445281         2  2016-01-31 23:26:06   2016-01-31 23:31:22   \n",
       "1445282         2  2016-01-31 23:50:36   2016-01-31 23:56:19   \n",
       "1445283         2  2016-01-31 23:57:47   2016-02-01 00:06:58   \n",
       "1445284         2  2016-01-31 23:59:54   2016-02-01 00:07:06   \n",
       "\n",
       "        Store_and_fwd_flag  RateCodeID  Pickup_longitude  Pickup_latitude  \\\n",
       "1445280                  N           1        -73.807716        40.700451   \n",
       "1445281                  N           1        -73.951408        40.714001   \n",
       "1445282                  N           1        -73.954842        40.730213   \n",
       "1445283                  N           1        -73.953491        40.817211   \n",
       "1445284                  N           1        -73.892578        40.747250   \n",
       "\n",
       "         Dropoff_longitude  Dropoff_latitude  Passenger_count     ...      \\\n",
       "1445280         -73.768478         40.698082                1     ...       \n",
       "1445281         -73.941483         40.724766                2     ...       \n",
       "1445282         -73.944626         40.726303                2     ...       \n",
       "1445283         -73.977127         40.779583                1     ...       \n",
       "1445284         -73.910049         40.775539                1     ...       \n",
       "\n",
       "         Fare_amount  Extra  MTA_tax  Tip_amount  Tolls_amount  Ehail_fee  \\\n",
       "1445280         10.5    0.5      0.5        0.00           0.0        NaN   \n",
       "1445281          6.0    0.5      0.5        1.00           0.0        NaN   \n",
       "1445282          6.5    0.5      0.5        2.34           0.0        NaN   \n",
       "1445283         10.5    0.5      0.5        1.50           0.0        NaN   \n",
       "1445284         10.0    0.5      0.5        2.82           0.0        NaN   \n",
       "\n",
       "         improvement_surcharge  Total_amount  Payment_type  Trip_type   \n",
       "1445280                    0.3         11.80             2         1.0  \n",
       "1445281                    0.3          8.30             1         1.0  \n",
       "1445282                    0.3         10.14             1         1.0  \n",
       "1445283                    0.3         13.30             1         1.0  \n",
       "1445284                    0.3         14.12             1         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we have a lot of columns, so some of the columns are getting cut off; we can easily subset to have less columns by using indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pickup_longitude</th>\n",
       "      <th>Pickup_latitude</th>\n",
       "      <th>Dropoff_longitude</th>\n",
       "      <th>Dropoff_latitude</th>\n",
       "      <th>Trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.928642</td>\n",
       "      <td>40.680611</td>\n",
       "      <td>-73.924278</td>\n",
       "      <td>40.698044</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.952675</td>\n",
       "      <td>40.723175</td>\n",
       "      <td>-73.923920</td>\n",
       "      <td>40.761379</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.971611</td>\n",
       "      <td>40.676105</td>\n",
       "      <td>-74.013161</td>\n",
       "      <td>40.646072</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.989502</td>\n",
       "      <td>40.669579</td>\n",
       "      <td>-74.000648</td>\n",
       "      <td>40.689034</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.964729</td>\n",
       "      <td>40.682854</td>\n",
       "      <td>-73.940720</td>\n",
       "      <td>40.663013</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pickup_longitude  Pickup_latitude  Dropoff_longitude  Dropoff_latitude  \\\n",
       "0        -73.928642        40.680611         -73.924278         40.698044   \n",
       "1        -73.952675        40.723175         -73.923920         40.761379   \n",
       "2        -73.971611        40.676105         -74.013161         40.646072   \n",
       "3        -73.989502        40.669579         -74.000648         40.689034   \n",
       "4        -73.964729        40.682854         -73.940720         40.663013   \n",
       "\n",
       "   Trip_distance  \n",
       "0           1.46  \n",
       "1           3.56  \n",
       "2           3.79  \n",
       "3           3.01  \n",
       "4           2.55  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_information = taxi_data[[\"Pickup_longitude\", \"Pickup_latitude\", \"Dropoff_longitude\", \"Dropoff_latitude\", \"Trip_distance\"]]\n",
    "location_information.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at any arbitrary set of rows in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>Lpep_dropoff_datetime</th>\n",
       "      <th>Store_and_fwd_flag</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>Pickup_longitude</th>\n",
       "      <th>Pickup_latitude</th>\n",
       "      <th>Dropoff_longitude</th>\n",
       "      <th>Dropoff_latitude</th>\n",
       "      <th>Passenger_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_amount</th>\n",
       "      <th>Extra</th>\n",
       "      <th>MTA_tax</th>\n",
       "      <th>Tip_amount</th>\n",
       "      <th>Tolls_amount</th>\n",
       "      <th>Ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Payment_type</th>\n",
       "      <th>Trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:49:38</td>\n",
       "      <td>2016-01-01 01:01:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.911057</td>\n",
       "      <td>40.768673</td>\n",
       "      <td>-73.849457</td>\n",
       "      <td>40.724583</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:57:12</td>\n",
       "      <td>2016-01-01 01:02:13</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.880302</td>\n",
       "      <td>40.828606</td>\n",
       "      <td>-73.895561</td>\n",
       "      <td>40.821033</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:57:17</td>\n",
       "      <td>2016-01-01 01:01:33</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.869339</td>\n",
       "      <td>40.748859</td>\n",
       "      <td>-73.863525</td>\n",
       "      <td>40.737297</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:52:10</td>\n",
       "      <td>2016-01-01 01:02:17</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.965530</td>\n",
       "      <td>40.683224</td>\n",
       "      <td>-73.943916</td>\n",
       "      <td>40.683205</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VendorID lpep_pickup_datetime Lpep_dropoff_datetime Store_and_fwd_flag  \\\n",
       "2014         2  2016-01-01 00:49:38   2016-01-01 01:01:55                  N   \n",
       "2015         2  2016-01-01 00:57:12   2016-01-01 01:02:13                  N   \n",
       "2016         2  2016-01-01 00:57:17   2016-01-01 01:01:33                  N   \n",
       "2017         2  2016-01-01 00:52:10   2016-01-01 01:02:17                  N   \n",
       "\n",
       "      RateCodeID  Pickup_longitude  Pickup_latitude  Dropoff_longitude  \\\n",
       "2014           1        -73.911057        40.768673         -73.849457   \n",
       "2015           1        -73.880302        40.828606         -73.895561   \n",
       "2016           1        -73.869339        40.748859         -73.863525   \n",
       "2017           1        -73.965530        40.683224         -73.943916   \n",
       "\n",
       "      Dropoff_latitude  Passenger_count     ...      Fare_amount  Extra  \\\n",
       "2014         40.724583                1     ...             19.0    0.5   \n",
       "2015         40.821033                1     ...              6.0    0.5   \n",
       "2016         40.737297                1     ...              5.5    0.5   \n",
       "2017         40.683205                1     ...              8.0    0.5   \n",
       "\n",
       "      MTA_tax  Tip_amount  Tolls_amount  Ehail_fee  improvement_surcharge  \\\n",
       "2014      0.5         0.0           0.0        NaN                    0.3   \n",
       "2015      0.5         0.0           0.0        NaN                    0.3   \n",
       "2016      0.5         0.0           0.0        NaN                    0.3   \n",
       "2017      0.5         0.0           0.0        NaN                    0.3   \n",
       "\n",
       "      Total_amount  Payment_type  Trip_type   \n",
       "2014          20.3             2         1.0  \n",
       "2015           7.3             2         1.0  \n",
       "2016           6.8             2         1.0  \n",
       "2017           9.3             1         1.0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data[2014:2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides extracting sets of columns, we can also get a single column by just using its name (assuming it has no spaces or special characters); here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.46\n",
       "1    3.56\n",
       "2    3.79\n",
       "3    3.01\n",
       "4    2.55\n",
       "Name: Trip_distance, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = taxi_data.Trip_distance\n",
    "distances[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform common summary operations very easily using `pandas`; for example, let's have it summarize the column representing the total amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.445285e+06\n",
       "mean     1.441838e+01\n",
       "std      1.201146e+01\n",
       "min     -4.975000e+02\n",
       "25%      7.800000e+00\n",
       "50%      1.116000e+01\n",
       "75%      1.730000e+01\n",
       "max      1.000800e+03\n",
       "Name: Total_amount, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.Total_amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something should stand out like a sore thumb: some trip cost negative ~500 dollars! To simplify our dataset, let's just get rid of all the trips that had nonpositive total amount using conditional indexing where each row is kept or not based on a boolean condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of rows: 1438657\n",
      "Percentage of trips with negative total amount: 0.46%\n"
     ]
    }
   ],
   "source": [
    "sensible_trips = taxi_data[taxi_data.Total_amount > 0]\n",
    "print(\"New number of rows: %d\" % len(sensible_trips.index))\n",
    "print(\"Percentage of trips with negative total amount: %.2f%%\" % \\\n",
    "      (100 * (1.0 - float(len(sensible_trips.index)) / len(taxi_data.index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank goodness that most of our trips don't have this weird behavior.\n",
    "\n",
    "Let's try to make a new column looking at what percentage of the total fare was from the trip; this is easy to do in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.438657e+06\n",
       "mean     7.098524e-02\n",
       "std      9.227385e-02\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      1.666667e-01\n",
       "max      1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensible_trips.tip_percentage = sensible_trips.Tip_amount / sensible_trips.Total_amount\n",
    "sensible_trips.tip_percentage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this simple calculation, we can say that a tip isn't given in over half of rides since the median value is 0; that's pretty weird, but it's cool that we were able to discover that with just a few `pandas` operations!\n",
    "\n",
    "We can also do pretty cool statistics using the `groupby` function; essentially, it lets you specify groups of rows based on a variable, and then we can do statistics on each group. This lets us do things like explore whether the tip amount is related to the number of people who were in the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std. dev.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passenger_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.094425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.092231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071527</td>\n",
       "      <td>0.093398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074753</td>\n",
       "      <td>0.094416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065178</td>\n",
       "      <td>0.094548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.070330</td>\n",
       "      <td>0.090389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073297</td>\n",
       "      <td>0.089202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.079779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.059235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.074138</td>\n",
       "      <td>0.086458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean  std. dev.\n",
       "Passenger_count                     \n",
       "0                0.053812   0.094425\n",
       "1                0.070866   0.092231\n",
       "2                0.071527   0.093398\n",
       "3                0.074753   0.094416\n",
       "4                0.065178   0.094548\n",
       "5                0.070330   0.090389\n",
       "6                0.073297   0.089202\n",
       "7                0.045288   0.079779\n",
       "8                0.029817   0.059235\n",
       "9                0.074138   0.086458"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = sensible_trips.tip_percentage.groupby(sensible_trips.Passenger_count).mean()\n",
    "stds = sensible_trips.tip_percentage.groupby(sensible_trips.Passenger_count).std()\n",
    "pd.DataFrame({'mean' : means, 'std. dev.' : stds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's awkward.. There were some rides where 0 people were in the taxi! Anyhow, there doesn't seem to be a whole lot of difference in the mean across different passenger counts given the variation in those values (as indicated by the standard deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our taxi data was super nice in many ways: among them, it had didn't have any missing values. In this next part, we'll explore what to do if we do have missing values in our data. Missing values can come up for any number of reasons such as sensor failure or a value not being applicable for a particular row; traditionally, they are represented as a special character such as `?` or `NA` in a CSV file though sometimes the value could just be blank. It's often a good practice to look at a CSV if you suspect it has missing values to see what the convention is as there is no standard.\n",
    "\n",
    "To get a CSV with missing values, we'll be using a different dataset the [Air Quality](http://archive.ics.uci.edu/ml/datasets/Air+Quality) dataset from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html). These datasets come in handy when you need any suitable set of data to practice your machine learning rather than explore through data science. It is already located in your `datasets` folder as `AirQualityUCI.csv`, so let's load it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "0  10/03/2004  18.00.00    2,6       1360.0     150.0     11,9         1046.0   \n",
       "1  10/03/2004  19.00.00      2       1292.0     112.0      9,4          955.0   \n",
       "2  10/03/2004  20.00.00    2,2       1402.0      88.0      9,0          939.0   \n",
       "3  10/03/2004  21.00.00    2,2       1376.0      80.0      9,2          948.0   \n",
       "4  10/03/2004  22.00.00    1,6       1272.0      51.0      6,5          836.0   \n",
       "\n",
       "   NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH  \\\n",
       "0    166.0        1056.0    113.0        1692.0       1268.0  13,6  48,9   \n",
       "1    103.0        1174.0     92.0        1559.0        972.0  13,3  47,7   \n",
       "2    131.0        1140.0    114.0        1555.0       1074.0  11,9  54,0   \n",
       "3    172.0        1092.0    122.0        1584.0       1203.0  11,0  60,0   \n",
       "4    131.0        1205.0    116.0        1490.0       1110.0  11,2  59,6   \n",
       "\n",
       "       AH  Unnamed: 15  Unnamed: 16  \n",
       "0  0,7578          NaN          NaN  \n",
       "1  0,7255          NaN          NaN  \n",
       "2  0,7502          NaN          NaN  \n",
       "3  0,7867          NaN          NaN  \n",
       "4  0,7888          NaN          NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_data = pd.read_csv(\"datasets/AirQualityUCI.csv\", sep = \";\")\n",
    "air_quality_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that should jump out is those unnamed columns at the end, let's dig deeper. We'll use the `isnan` function from `numpy` to check if there are any real values in the column and the `all` function also from `numpy` to quickly tell us if all the values are junk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Garbage in 15? True\n",
      "All Garbage in 16? True\n"
     ]
    }
   ],
   "source": [
    "all_nan_15 = np.all(np.isnan(air_quality_data[\"Unnamed: 15\"].values))\n",
    "all_nan_16 = np.all(np.isnan(air_quality_data[\"Unnamed: 16\"].values))\n",
    "print(\"All Garbage in 15? %s\" % all_nan_15)\n",
    "print(\"All Garbage in 16? %s\" % all_nan_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the values are not usable, let's go ahead and drop those columns using the `drop` function. Note that it's best practice to define a new dataframe without those columns rather than deleting them from the original dataframe because running your code twice would fail (you can't delete them again after having deleted them once). Also, the `axis = 1` just means drop a column rather than drop a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "0  10/03/2004  18.00.00    2,6       1360.0     150.0     11,9         1046.0   \n",
       "1  10/03/2004  19.00.00      2       1292.0     112.0      9,4          955.0   \n",
       "2  10/03/2004  20.00.00    2,2       1402.0      88.0      9,0          939.0   \n",
       "3  10/03/2004  21.00.00    2,2       1376.0      80.0      9,2          948.0   \n",
       "4  10/03/2004  22.00.00    1,6       1272.0      51.0      6,5          836.0   \n",
       "\n",
       "   NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH  \\\n",
       "0    166.0        1056.0    113.0        1692.0       1268.0  13,6  48,9   \n",
       "1    103.0        1174.0     92.0        1559.0        972.0  13,3  47,7   \n",
       "2    131.0        1140.0    114.0        1555.0       1074.0  11,9  54,0   \n",
       "3    172.0        1092.0    122.0        1584.0       1203.0  11,0  60,0   \n",
       "4    131.0        1205.0    116.0        1490.0       1110.0  11,2  59,6   \n",
       "\n",
       "       AH  \n",
       "0  0,7578  \n",
       "1  0,7255  \n",
       "2  0,7502  \n",
       "3  0,7867  \n",
       "4  0,7888  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_air_quality_data = air_quality_data.drop([\"Unnamed: 15\", \"Unnamed: 16\"], axis = 1)\n",
    "clean_air_quality_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's go looking for those missing values. We'll use the `isnull` function from `pandas`, which would produce a new data frame where every value has been replaced by whether it's junk or not. We can then summarize it by using the `sum` function, which by default does column sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             114\n",
       "Time             114\n",
       "CO(GT)           114\n",
       "PT08.S1(CO)      114\n",
       "NMHC(GT)         114\n",
       "C6H6(GT)         114\n",
       "PT08.S2(NMHC)    114\n",
       "NOx(GT)          114\n",
       "PT08.S3(NOx)     114\n",
       "NO2(GT)          114\n",
       "PT08.S4(NO2)     114\n",
       "PT08.S5(O3)      114\n",
       "T                114\n",
       "RH               114\n",
       "AH               114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_air_quality_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, it isn't the case that a certain variable is missing more than others, so a good guess would be that 114 rows have no values for each column. Let's check out a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  \\\n",
       "9357  NaN  NaN    NaN          NaN       NaN      NaN            NaN      NaN   \n",
       "9358  NaN  NaN    NaN          NaN       NaN      NaN            NaN      NaN   \n",
       "9359  NaN  NaN    NaN          NaN       NaN      NaN            NaN      NaN   \n",
       "9360  NaN  NaN    NaN          NaN       NaN      NaN            NaN      NaN   \n",
       "9361  NaN  NaN    NaN          NaN       NaN      NaN            NaN      NaN   \n",
       "\n",
       "      PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)    T   RH   AH  \n",
       "9357           NaN      NaN           NaN          NaN  NaN  NaN  NaN  \n",
       "9358           NaN      NaN           NaN          NaN  NaN  NaN  NaN  \n",
       "9359           NaN      NaN           NaN          NaN  NaN  NaN  NaN  \n",
       "9360           NaN      NaN           NaN          NaN  NaN  NaN  NaN  \n",
       "9361           NaN      NaN           NaN          NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_air_quality_data[clean_air_quality_data.Date.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we had suspected! (Note that we had to check the assumption that the missing values were just located in the same 114 rows.) We'll try two different approaches to fixing this issue: getting rid of the problematic rows and imputing (read: replacing, imputing is just fancy talk in the business) the missing values with the previous non-missing value. The second is a good strategy since this is time-series data, but if the observations were unconnected, we might use the mean of the column instead.\n",
    "\n",
    "First up is getting rid of the problematic rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0\n",
      "Time             0\n",
      "CO(GT)           0\n",
      "PT08.S1(CO)      0\n",
      "NMHC(GT)         0\n",
      "C6H6(GT)         0\n",
      "PT08.S2(NMHC)    0\n",
      "NOx(GT)          0\n",
      "PT08.S3(NOx)     0\n",
      "NO2(GT)          0\n",
      "PT08.S4(NO2)     0\n",
      "PT08.S5(O3)      0\n",
      "T                0\n",
      "RH               0\n",
      "AH               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "0  10/03/2004  18.00.00    2,6       1360.0     150.0     11,9         1046.0   \n",
       "1  10/03/2004  19.00.00      2       1292.0     112.0      9,4          955.0   \n",
       "2  10/03/2004  20.00.00    2,2       1402.0      88.0      9,0          939.0   \n",
       "3  10/03/2004  21.00.00    2,2       1376.0      80.0      9,2          948.0   \n",
       "4  10/03/2004  22.00.00    1,6       1272.0      51.0      6,5          836.0   \n",
       "\n",
       "   NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH  \\\n",
       "0    166.0        1056.0    113.0        1692.0       1268.0  13,6  48,9   \n",
       "1    103.0        1174.0     92.0        1559.0        972.0  13,3  47,7   \n",
       "2    131.0        1140.0    114.0        1555.0       1074.0  11,9  54,0   \n",
       "3    172.0        1092.0    122.0        1584.0       1203.0  11,0  60,0   \n",
       "4    131.0        1205.0    116.0        1490.0       1110.0  11,2  59,6   \n",
       "\n",
       "       AH  \n",
       "0  0,7578  \n",
       "1  0,7255  \n",
       "2  0,7502  \n",
       "3  0,7867  \n",
       "4  0,7888  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strictly_clean_air_quality_data = clean_air_quality_data[np.logical_not(clean_air_quality_data.Date.isnull())]\n",
    "print(strictly_clean_air_quality_data.isnull().sum())\n",
    "strictly_clean_air_quality_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Let's try the other way now. `pandas` makes it super easy for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>13.00.00</td>\n",
       "      <td>2,1</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>9,5</td>\n",
       "      <td>961.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>28,3</td>\n",
       "      <td>13,5</td>\n",
       "      <td>0,5139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>14.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>28,5</td>\n",
       "      <td>13,1</td>\n",
       "      <td>0,5028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>14.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>28,5</td>\n",
       "      <td>13,1</td>\n",
       "      <td>0,5028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>14.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>28,5</td>\n",
       "      <td>13,1</td>\n",
       "      <td>0,5028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>04/04/2005</td>\n",
       "      <td>14.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>28,5</td>\n",
       "      <td>13,1</td>\n",
       "      <td>0,5028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  \\\n",
       "9355  04/04/2005  13.00.00    2,1       1003.0    -200.0      9,5   \n",
       "9356  04/04/2005  14.00.00    2,2       1071.0    -200.0     11,9   \n",
       "9357  04/04/2005  14.00.00    2,2       1071.0    -200.0     11,9   \n",
       "9358  04/04/2005  14.00.00    2,2       1071.0    -200.0     11,9   \n",
       "9359  04/04/2005  14.00.00    2,2       1071.0    -200.0     11,9   \n",
       "\n",
       "      PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "9355          961.0    235.0         702.0    156.0        1041.0   \n",
       "9356         1047.0    265.0         654.0    168.0        1129.0   \n",
       "9357         1047.0    265.0         654.0    168.0        1129.0   \n",
       "9358         1047.0    265.0         654.0    168.0        1129.0   \n",
       "9359         1047.0    265.0         654.0    168.0        1129.0   \n",
       "\n",
       "      PT08.S5(O3)     T    RH      AH  \n",
       "9355        770.0  28,3  13,5  0,5139  \n",
       "9356        816.0  28,5  13,1  0,5028  \n",
       "9357        816.0  28,5  13,1  0,5028  \n",
       "9358        816.0  28,5  13,1  0,5028  \n",
       "9359        816.0  28,5  13,1  0,5028  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_air_quality_data = clean_air_quality_data.fillna(method = \"ffill\")\n",
    "imputed_air_quality_data[9355:9360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be doing okay since the previously missing rows now take the values from row with index number 9356, but of course, we could always do better. For example, the `Date` column probably should still increment! `pandas` provides us a few interpolation options that would account for things like this, but you should always make sure that it's doing something sensible by checking known missing value cases!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
